{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptRymsaGQvXr"
   },
   "source": [
    "# Install packages\n",
    "Some packages still have to be installed, like SHAP, hdbscan, umap-learn and skope-rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwYaWcm-N6Rh"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install shap hdbscan umap-learn skope-rules scikit-learn==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fgofWc9ga6b"
   },
   "source": [
    "Load git repo to have access to data if not cloned yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMC1JRp8f-Lj"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/pyladiesams/intro-to-explainabilty-in-finance-oct2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUx3CCuebbVA"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fkAODEpL0um"
   },
   "outputs": [],
   "source": [
    "import collections.abc\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import six\n",
    "import sklearn\n",
    "import umap\n",
    "import xgboost as xgb\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "sklearn.externals.six = six\n",
    "from skrules import SkopeRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrnjVW21PfYe"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-R0CE6J88PA6"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this workshop, we'll work on a use case involving customer churn prediction. We'll use EDA to explore the dataset and SHAP for interpreting the model's predictions, helping us understand why customers might leave and if the predicts correctly. <br><br>\n",
    "\n",
    "**EDA & Interpretability: Why We Need Both**\n",
    "* Exploratory Data Analysis (EDA) helps us understand the structure and patterns in our data. Interpretability, on the other hand, ensures that our models' inner workings and predictions are understandable and trustworthy. Combining EDA with interpretability techniques allows for more informed decision-making and reliable insights, as the findings from EDA should be reflected in the model's logic. This approach enables us to audit models and to better explain results to stakeholders.\n",
    "\n",
    "**Methods for EDA & Interpretability**\n",
    "* Common EDA methods include summary statistics, data visualization (such as histograms, scatter plots), heat maps and correlation analysis. For interpretability, methods are often divided into local and global approaches. Local interpretability focuses on explaining individual predictions, while global interpretability looks at overall model behavior. Examples include feature importance, partial dependence plots, and SHAP (SHapley Additive exPlanations), which we use for this workshop due to its widespread adoption. Links for further details will be provided at the end of the notebook for those interested in exploring further.\n",
    "\n",
    "**SHAP: High-Level Overview**\n",
    "* SHAP is a method that explains individual predictions by attributing each feature’s contribution to the output. It builds on concepts from game theory, specifically Shapley values, to fairly distribute the total prediction among the contributing features. This ensures consistent, interpretable, and fair explanations by considering all possible feature combinations. While SHAP is primarily a local explanation method—providing insights into single predictions—it can also be aggregated across many predictions to create global explanations, offering insights into overall model behavior.  \n",
    "It’s important to note that SHAP shows correlations between features and model predictions, but it [does not imply causal relationships](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/Be%20careful%20when%20interpreting%20predictive%20models%20in%20search%20of%20causal%20insights.html).  \n",
    "For a more [detailed explanation of SHAP](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bpsorY48Ty1"
   },
   "source": [
    "# The mortgage churn dataset\n",
    "\n",
    "We will use a dataset of customers of a random bank. The dataset contains information on the mortgage churn of customers. Besides the dataset consists of data on characteristics of the customer but also information on the mortgage. <br><br>\n",
    "\n",
    "\n",
    "#### **!!! IMPORTANT !!!**\n",
    "This data is *generated* for the purpose of this workshop. The dataset:\n",
    "* doesn't include any customers of ABN AMRO\n",
    "* isn't a represenation of the population of customers at ABN AMRO  \n",
    "\n",
    "Credits: dataset is adapted based on: https://archive.ics.uci.edu/dataset/34/diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nt-dsWkx8V9P"
   },
   "source": [
    "**The data contains the following features:**\n",
    "\n",
    "|Feature                      | Description   |\n",
    "|:----------------------------|:--------------|\n",
    "| churn                        | If the customer has churned on the mortgage (0 = no, 1 = yes) |\n",
    "| activity level               | Activity related to mortgages on the web/mobile of the bank (1 = lowest -  5 = highest) |\n",
    "| parties_count                | Number of parties involved into the mortgage contract (1 - 2) |\n",
    "| years_until_frp              | Years until fixed rate period ends (in years) |\n",
    "| recently_contacted           | If the customer contacted the bank. (0 = no, 1 = yes) |\n",
    "| recently_changed_energy level| If the customer had changes in energy level in the past 6 month. (0 = no, 1 = yes) |\n",
    "| recently_took_loan           | If the customer has recently obtained a loan from the bank. (0 = no, 1 = yes) |\n",
    "| age                          | Age of the customer (in years) |\n",
    "| used_calculator              | If a customer have recently used a mortgage calculator tool (0 = no, 1 = yes) |\n",
    "| customer_before_mortgage     | If the customer were a also a customer of the bank before obtaining a mortgage product. (0 = no, 1 = yes) |\n",
    "| market_value                 | The current market value of the property. (1=  lowest -  8 = highest) |\n",
    "| missed_payment               | If the customer had missed a payment at least once (0 = no, 1 = yes) |\n",
    "| city_size                    | The cize of the city where the property is located.  (1 = smallest -  6 = highest) |\n",
    "| balance                      | Amount of money left to pay off (in euro) - this feature is created to imitate a leaky feature |\n",
    "\n",
    "<br>\n",
    "\n",
    "**Target variable**\\\n",
    "Churn is our target variable in this workshop.<br><br>\n",
    "\n",
    "**Other remarks on the data**\n",
    "* All data is ordered.\n",
    "* Age and balance are continuous, rest is ordinal or binary.\n",
    "* The dataset has already been cleaned, so no extra transformations are needed.\n",
    "<br>\n",
    "\n",
    "**Exercises**\\\n",
    "Most of exercises are interpretation of our results. However, at some places you will be asked to fill in variables to learn how to use shap plot. They are marked with a ⭐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nr7Ta1v-79SY"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('mortgage_churn.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZyR4gGpW1R4"
   },
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "Exploratory Data Analysis (EDA)\n",
    "Explanation: In this part of the workshop, we will take a closer look at the data and its distribution. EDA helps us uncover patterns, spot anomalies, and test hypotheses. We will focus on two main activities:\n",
    "\n",
    "* **Explore Plots Between Features and the Target Variable**: We will create visualizations such as scatter plots, box plots, and bar charts to see relationships between features and the target variable. This helps us identify trends and potential predictors.\n",
    "* **Explore Correlations**: We will analyze the relationships between different features using correlation matrices and heatmaps. This helps us understand how features interact with each other and identify multicollinearity issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHiNl2X18dhU"
   },
   "source": [
    "<a id=\"EDA\"></a>\n",
    "## EDA: Plots features versus target variable\n",
    "Let's explore the connections between features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeceRoQdDt1C"
   },
   "outputs": [],
   "source": [
    "def create_facet_grit_hist(df, target='churn', multiple='layer'):\n",
    "    \"\"\"\n",
    "    Create a facet grid of histograms of all features in the dataset,\n",
    "    where we compare the target outcome.\n",
    "\n",
    "    Args:\n",
    "        df (dataFrame): Input dataset\n",
    "        target (str): Target column name\n",
    "        multiple (str): Approach how the graph should be shown; 'layer' or 'dodge'\n",
    "\n",
    "    Returns:\n",
    "        Nothing\n",
    "    \"\"\"\n",
    "\n",
    "    df_melted = pd.melt(df, id_vars=target, value_vars=[col for col in df.columns if col != target])\n",
    "    df_melted['value'] = df_melted['value'].astype(int)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    graphs = sns.FacetGrid(df_melted,\n",
    "                           col='variable',\n",
    "                           hue=target,\n",
    "                           col_wrap=3,\n",
    "                           sharey=False,\n",
    "                           sharex=False,\n",
    "                           aspect=2)\n",
    "\n",
    "    graphs.map(sns.histplot, 'value', kde=False, element='bars', stat='count', multiple='dodge')\n",
    "\n",
    "    # Add legend and titles\n",
    "    graphs.add_legend(title=target, loc='upper right')\n",
    "    graphs.set_titles(col_template=\"{col_name}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "create_facet_grit_hist(df=df, target='churn', multiple='layer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiAsEiSU8faL"
   },
   "source": [
    "<details>\n",
    "<summary><b>Discussion of Results</b> (click to open)</summary>  \n",
    "\n",
    "**What relationships do we see between feature and the target variable from the plots?**\n",
    "* Balance, less - more likely to churn. We can clearly see here that balance is fully predictive. This is our leaky feature with information about mortgage balance left at the account, that would not be there at the time of prediction.\n",
    "* More activity level, more likely to churn\n",
    "* Less parties involved, more likely to churn\n",
    "* Years until fixed rate period, less years more likely to churn\n",
    "* If recenttly energy label changed, then more likely to churn\n",
    "* If recently took loan, then more likely to churn\n",
    "* Older people, more likely to churn\n",
    "* Used calculator, more likely to churn\n",
    "* Customer before mortgage - if not, more likely to churn\n",
    "* Higher market value, less likely to churn\n",
    "* Bigger city, less likely to churn\n",
    "</details>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrKlrWluAEH3"
   },
   "source": [
    "## **EDA: Correlations**  \n",
    "\n",
    "Let's use Spearman correlations to have a closer look at the correlations between features. We use the Spearman correlation.\n",
    "\n",
    " Spearman correlation evaluates how well the relationship between the variables can be described using a monotonic function. Spearman correlation requires at least two variables that can be either ordinal or continuous. The Spearman correlation coefficient ranges from -1 to 1, where 1 indicates a perfect positive correlation, -1 indicates a perfect negative correlation. The Spearman correlation is considered weak when the correlation coefficient is close to 0.\n",
    "\n",
    "* Weak correlation: ( -0.3 corr < 0.3 )  \n",
    "* Moderate correlation: (-0.5 < corr < -0.3 or 0.3 < corr < 0.5 )  \n",
    "* Strong correlation: ( -0.5 < or > 0.5 )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTX1bm-w_bO3"
   },
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix using Spearman's rank correlation.\n",
    "# You can fill in the data you want to analyze by replacing 'df' with your DataFrame.\n",
    "\n",
    "corr_matrix = df.corr(method='spearman')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Create a heatmap to visualize the correlation matrix.\n",
    "# 'annot=True' displays the correlation values on the heatmap.\n",
    "# 'cmap=\"coolwarm\"' sets the color map for the heatmap (you can change this if needed).\n",
    "# 'linewidths=0.5' adds space between the squares, making the heatmap more readable.\n",
    "# 'fmt=\".2f\"' ensures the correlation values are formatted to two decimal places.\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", linewidths=0.5, fmt='.2f')\n",
    "plt.title(\"Spearman Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXq-j7zQj0jd"
   },
   "source": [
    "<details>\n",
    "<summary>What do we notice from the correlation matrix?</summary>  \n",
    "\n",
    "**What do we notice from the correlation matrix?**\\\n",
    "The Spearman correlation matrix, shows a very high correlation between balance and churn. This is our leak feature so we know the reason for this high correlation: balance after churning vs before. In normal situation this needs to be investigated before building a model.\n",
    "\n",
    "Besides that we have moderately correlated features in the dataset.\n",
    "\n",
    "*Positively moderately correlated:*\n",
    "* used_calculator and activity_level\n",
    "* city_size and market_value  \n",
    "\n",
    "*Negatively moderately correlated:*\n",
    "* market_value and activity_level\n",
    "* market_value and used_calculator\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYQDTTho8iho"
   },
   "source": [
    "# Model\n",
    "Many different models can be used for this specific use case. However, we will use XGBoost as it works well with our type of data and runs **fast** with the SHAP library when producing explanations (see exercise 1). If you're interested, you can check always for yourself later on how fast SHAP works with other models.\n",
    "\n",
    "*Remark:*<br>\n",
    "We have seen before that balance is a suspicious feature, but for this exercise let's ignore it for now. Let's see how the model will look with and without the feature balance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwMh4jcruCcd"
   },
   "source": [
    "## Model: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EC1X9GrL8mqP"
   },
   "outputs": [],
   "source": [
    "# This is the model **with** using the 'balance' feature\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "# Here, 'churn' is the target variable we are predicting\n",
    "X = df.drop(['churn'],axis=1)\n",
    "y = df['churn']\n",
    "# Splitting the data into training and test sets (80% train, 20% test)\n",
    "# 'random_state=42' ensures reproducibility of the train-test split\n",
    "X_train_b, X_test_b, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the XGBoost classifier with the training set\n",
    "xg_cls_b = xgb.XGBClassifier().fit(X_train_b, y_train)\n",
    "# Predicting the labels for the test set\n",
    "y_pred_b = xg_cls_b.predict(X_test_b)\n",
    "\n",
    "# Generating and printing the classification report, which includes precision, recall, f1-score, and support\n",
    "class_report = classification_report(y_test, y_pred_b)\n",
    "print(\"\\nClassification Report with balance feature:\")\n",
    "print(class_report)\n",
    "\n",
    "\n",
    "# This is the model **without** using the 'balance' feature\n",
    "\n",
    "# Dropping the 'balance' feature from the training and test sets\n",
    "X_train = X_train_b.drop(['balance'], axis=1)\n",
    "X_test = X_test_b.drop(['balance'], axis=1)\n",
    "# Training the XGBoost classifier on the modified dataset (without 'balance')\n",
    "# Initialize a tuned XGBoost classifier with specific hyperparameters\n",
    "# These parameters include:\n",
    "# - colsample_bytree: The fraction of features to randomly sample for each tree\n",
    "# - learning_rate: The step size at each iteration (controls how quickly the model learns)\n",
    "# - max_depth: The maximum depth of each tree\n",
    "# - n_estimators: The number of trees (boosting rounds)\n",
    "# - subsample: The fraction of samples to use for training each tree (helps prevent overfitting)\n",
    "xg_cls = xgb.XGBClassifier(colsample_bytree= 0.9, learning_rate= 0.1, max_depth= 4, n_estimators= 150, subsample= 0.8, random_state=42).fit(X_train, y_train)\n",
    "y_pred = xg_cls.predict(X_test)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report without balance feature:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-fi6jFN8rsw"
   },
   "source": [
    "**What do we notice from the classfication reports of the model?**<bR>\n",
    "Using balance gives us 99% accuracy, which is very unlikely. In real world data this does not really happen. The model without balance seems more realistic.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWGQMMHDuLB1"
   },
   "source": [
    "## Model: Feature importance\n",
    "In this part we look at the XGBoost feature importance. Again we look at the feature importance of the model with and without balance.\n",
    "\n",
    "**What is feature importance in XGBoost?**<br>\n",
    "Feature importance in tree models indicates the relative contribution of each feature to the model's accuracy, helping to identify which variables are most influential in driving the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NlaqmpF8of0"
   },
   "outputs": [],
   "source": [
    "# Titles for the two plots (with and without the 'balance' feature)\n",
    "titles = [' with balance', ' without balance']\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "# Loop through the two models and their corresponding feature sets\n",
    "for i, (model, feature_names) in enumerate(zip([xg_cls_b, xg_cls], [X.columns, X_train.columns])):\n",
    "    # Get the feature importance from the model\n",
    "    feature_importance = model.feature_importances_\n",
    "    # Create a DataFrame to hold feature names and their corresponding importance scores & sort\n",
    "    feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "    feature_importance = feature_importance.sort_values(by='Importance', ascending=True)\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Feature Importances'+titles[i])\n",
    "    plt.yticks(fontsize=8)\n",
    "plt.subplots_adjust(wspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajgHE7xsuzU7"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>What do we notice from the feature importance?</summary>\n",
    "\n",
    "**What do we notice from the feature importance?**<br>\n",
    "*Feature importance with balance:*<br>\n",
    "Balance is really a dominant feature. The feature importance value of balance is > 0.9. This means that it significantly predicts the target variable of churn. The feature importance of the other features is low.\n",
    "\n",
    "\n",
    "*Feature importance without balance:*<br>\n",
    "If balance is not included in the model then the feature importance shows a different graph. Now, activity_level is the most important feature with a feature importance value around 0.4. Activity_level is followed by parties_count.\n",
    "\n",
    "\n",
    "These results show us that first model reliance on a single feature masks the true complexity of the problem and results in a model that is not genuinely reflective of real-world scenarios.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74m3tCoL8wdq"
   },
   "source": [
    "# 1. Exercise One: Introduction to SHAP Visualizations\n",
    "<!-- SHAP (SHapley Additive exPlanations) is derived from game theory and it provides a framework for interpreting machine learning models. SHAP values provide insights into how different features influence the output of your model, allowing for a better understanding of model behavior and decision-making. SHAP can be applied to any machine learning model. It helps in identifying which features are driving predictions and enhancing transparency and trust in AI.<br><br>-->\n",
    "\n",
    "After this exercise you will have some familiarisation with SHAP plots and comparing it with EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSpZhZFqMXKW"
   },
   "source": [
    "## 1.1 SHAP for a leaky feature detection\n",
    "In this exercise, you will compare SHAP plots to insights from EDA looking on the impact of a leaky feature in the dataset. The goal is to observe how SHAP values reflect feature importance and compare it to what we have seen in EDA and model performance. By comparing the plots, you’ll understand the effects of data leakage and how removing this feature alters the feature importance and improves the model's robustness.\n",
    "\n",
    "**⭐ Exercise:**<br>\n",
    "Generate two SHAP summary plots:\n",
    "* one for a model trained with the leaky feature (X_train_b)\n",
    "* another without it (X_train).  <br>\n",
    "\n",
    "For SHAP to show us distribution of SHAP values, we need:\n",
    "* samples of the dataset that need to be filled in dataShap and\n",
    "* provide the model to be explained.\n",
    "\n",
    "The dataset you can use can be your test or training sample, random subsample or even whole dataset. Note that the bigger data sample the longer it will run. For this exercise we will use train.sample(1000) or test sample.\n",
    "\n",
    "As **reminder**, we have following variables with balance feature and without: X_test_b, X_train_b, xg_cls_b, X_test, X_train, xg_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FB2SnXK48tZa"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "plt.subplot(1,2,1)\n",
    "# Data subset that you want to visualize for SHAP values (including 'balance' feature)\n",
    "dataShap_b =  ## EXERCISE: Fill with data subset that you want to visualise for features including balance\n",
    "# Create a SHAP explainer for the model trained with 'balance'\n",
    "explainer_b = shap.TreeExplainer() ## EXERCISE: Fill corresponding trained model name\n",
    "# Calculate SHAP values for the data\n",
    "shap_values_all_b = explainer_b(dataShap_b)\n",
    "# Extract the SHAP values from the explanation object\n",
    "shap_values_b = shap_values_all_b.values\n",
    "# Generate the SHAP summary plot (with 'balance')\n",
    "# 'show=False' ensures the plot is not displayed until plt.show() is called at the end\n",
    "shap.summary_plot(shap_values_b, dataShap_b, plot_size=None, show=False)\n",
    "plt.title('Importance plot for model with leaky feature (balance)')\n",
    "# Subplot for the model **without** the 'balance' feature\n",
    "plt.subplot(1,2,2)\n",
    "dataShap =  ## EXERCISE: Fill with data subset that you want to visualise for features without balance feature\n",
    "explainer = shap.TreeExplainer() ## EXERCISE: Fill corresponding trained model name\n",
    "shap_values_all = explainer(dataShap)\n",
    "shap_values = shap_values_all.values\n",
    "shap.summary_plot(shap_values, dataShap, plot_size=None, show=False)\n",
    "plt.title('Importance plot for correct model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLsiPt7n8zAl"
   },
   "source": [
    "<details>\n",
    "<summary>Discussion of the results</summary>\n",
    "\n",
    "**Discussion of the results** <br>\n",
    "The SHAP summary plots rank features from most to least important based on their contribution to the model's predictions. In the plots, blue represents low feature values, while red represents high feature values. The right side of the plot shows the features pushing predictions towards customer churn, while the left side indicates non-churn. SHAP helps us visualize how the model is making decisions. <br><br>\n",
    "\n",
    "*Left SHAP summary plot:*<br>\n",
    "* The SHAP values for the \"balance\" feature align with the trend we observed in the EDA, reflecting its distribution.\n",
    "* In contrast, other features on the left plot appear compressed, indicating lower importance or less variability in their influence on the model's output.<br><br>\n",
    "\n",
    "\n",
    "*Right SHAP summary plot:*<br>\n",
    "* Like in the feature importance, without balance, the SHAP values of the other features are less compressed.\n",
    "* Activity_level is ranked as most important.\n",
    "* Age and years_until_frp can be considered as important.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7tjLI1-hOGX"
   },
   "source": [
    "## 1.2 SHAP single explanation\n",
    "In exercise 1.1 we have looked at the SHAP values on the total dataset. This is also known as global SHAP. SHAP also provides the possibility to look at an individual level, i.e. local SHAP.\n",
    "because 'global' is just all these single explanations plotted and ordered by mean absolute value of the SHAP values for each feature. In this exercise we visualize local SHAP for three different customers.<br>\n",
    "\n",
    "⭐ **Exercise:** <br>\n",
    "We’ve gathered the indices of misclassified, churned, and non-churned samples for you, which you can find in the loop. Please refer to the *samples* section in line 7 for more details. Your job is to\n",
    "fill samples in the waterfall plot. <br>\n",
    "Tip: waterfall plot needs more information than just shap_values themselves. Print beforehand *shap_values_all* and\n",
    "*shap_values* to explore what they hold inside. <br>\n",
    "Compare it with our global explanations. Do features have the same order?<br>\n",
    "Check as well what happens when we use a leaky model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfwrKDrK0nSE"
   },
   "outputs": [],
   "source": [
    "#Find sample that was misclassified, churned and non churned\n",
    "misclass_idx = np.where((y_test != y_pred))[0][0]\n",
    "class_1_idx = np.where((y_test == 1) & (y_pred == 1))[0][0]\n",
    "class_0_idx = np.where((y_test == 0) & (y_pred == 0))[0][0]\n",
    "\n",
    "titles = ['misclassified', 'nonchurn', 'churn']\n",
    "samples = [misclass_idx, class_0_idx, class_1_idx]\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(1, 3)\n",
    "for i, axx in enumerate([ax0,ax1,ax2]):\n",
    "    plt.sca(axx)\n",
    "    # Plot the SHAP waterfall plot for each prediction category using the i-th SHAP values\n",
    "    # shap_values_all[i] contains SHAP values for each category (e.g., misclassifications, non-churn, churn)\n",
    "    shap.plots.waterfall(,show=False) ## EXERCISE: Fill samples\n",
    "    axx.set_title(titles[i])\n",
    "    axx.yaxis.label.set_fontsize(10)\n",
    "plt.subplots_adjust(wspace=1)\n",
    "fig.set_size_inches(20, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYim2l7Iz-y3"
   },
   "source": [
    "<details>\n",
    "<summary>Discussion of the results</summary>\n",
    "\n",
    "\n",
    "**Discussion of results**<br>\n",
    "The above plots show us what the effect of the variable is on the outcome for that specific *customer*. A positive red arrow means the feature has a positive impact on churn and a negative blue arrow means the feature value for that customer impacts the churn negatively.\n",
    "\n",
    "This effect is not always intuitive or understandable, it's just a reflection of what the model learned from the train dataset. This is because causality cannot be proven with this kind of model.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sa910Y888Co"
   },
   "source": [
    "## 1.3  Bonus: Comparing SHAP explanations with different background samples\n",
    "In this exercise, you will compare SHAP explanations using different background samples. The goal is to see how feature importance changes when using default background data versus a subset of higher activity customers as the background. You will look at:\n",
    "\n",
    "* SHAP values that are generated using the default background sample.  \n",
    "* SHAP values that are generated using higher activity levels as the background for the explainer.  \n",
    "\n",
    "We use the SHAP with TreeExplainer. The SHAP TreeExplainer is a specialised implementation of the SHAP designed specifically for tree-based models like XGBoost. Background data is not needed, because the algorithm exploits the structure of tree-based models, allowing it to efficiently compute SHAP values without requiring a reference dataset for comparison. The internal splits of decision trees inherently capture the necessary distributional information to explain the model’s predictions. However, in other explainers providing background data is vital, so we want to touch upon how this affects our results.\n",
    "\n",
    "This shows how the choice of background data impacts the interpretation of feature importance for specific subsets of the population.  <br>\n",
    "\n",
    "**⭐ Exercise:**<br>\n",
    "The background data is used to define coalitions, which helps in calculating SHAP values. It is given as second argument in *explainer = shap.Explainer(model, background_data)*.\n",
    "\n",
    "The subset given in *explainer.shap_values(plotted_data)* will be used for generating the SHAP plots,\n",
    "allowing us to visualize how this specific subset behaves in relation to the model's predictions.\n",
    "<br><br>\n",
    "What do you do:\n",
    "Based on [EDA](#EDA) choose appropriate activity level that would describe a subset of people more likely to churn based on their activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QvrgPvC88_a"
   },
   "outputs": [],
   "source": [
    "# Subset of the test data where 'activity_level' is greater than X\n",
    "# This subset will be used in both SHAP plots\n",
    "dataShap_sub = X_test[X_test['activity_level']>] # EXERCISE: fill in desired activity level thresold used in both plots\n",
    "\n",
    "# Subplot 1: SHAP summary plot with the default background dataset (training data)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "plt.subplot(1,2,1)\n",
    "shap_values_sub = explainer.shap_values(dataShap_sub)\n",
    "shap.summary_plot(shap_values_sub, dataShap_sub, plot_size=None,show=False)\n",
    "plt.title('Importance plot with default background data')\n",
    "\n",
    "# Subplot 2: SHAP summary plot using the filtered subset as the new background dataset\n",
    "plt.subplot(1,2,2)\n",
    "explainer_newbackground = shap.TreeExplainer(xg_cls, dataShap_sub) # add our defined dataSubset as second argument\n",
    "shap_values_newbackground = explainer_newbackground.shap_values(dataShap_sub)\n",
    "shap.summary_plot(shap_values_newbackground, dataShap_sub, plot_size=None,show=False)\n",
    "plt.title('Importance plot with new background data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgQYST9bW1-X"
   },
   "source": [
    "<details>\n",
    "<summary>Discussion of the results</summary>\n",
    "\n",
    "**Discussion of the results**<br>\n",
    "We can see here that, for the same samples shown, we obtain different feature importance and distributions of activity levels. While we can now investigate in detail what is truly important for this subset of customers, it is also important to remember that background data cannot be any sample and should be carefully considered. <br>\n",
    "\n",
    "*Advantages:*<br>\n",
    "We can see variation of importance for subsets of data. <br>\n",
    "\n",
    "*Pitfalls:* <br>\n",
    "Taking random small sample for background data (to improve computational time) can lead to wrong interpretations.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPtVtPJr8-ka"
   },
   "source": [
    "# 2. Exercise Two: SHAP and features interactions\n",
    "\n",
    "Earlier, during the EDA we've looked at the correlations. We've seen some moderately correlated relationships between features. In this exercise we will look at the combination of SHAP and correlated features.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvuRC1AYhAqy"
   },
   "source": [
    "### 2.1 SHAP and clusters dendrogram\n",
    " In this exercise, we'll visualize these relationships using a dendrogram to cluster correlated features. In addition, we use this clusters to order the SHAP values according to this dendrogram.\n",
    "\n",
    "Grouping features in SHAP plots allows us to identify relationships among features, making it easier to understand their collective impact on model predictions. This simplification reduces complexity, enabling us to focus on key feature groups rather than individual features.\n",
    "\n",
    "Let's summarize the correlations of the moderately correlated variables in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzvq-KxnAKAN"
   },
   "outputs": [],
   "source": [
    "corr_matrix = corr_matrix.drop(index=['churn', 'balance'], columns=['churn', 'balance'])\n",
    "\n",
    "# Define correlation thresholds\n",
    "# weak_threshold: Minimum correlation value to be considered weak but not moderate\n",
    "# moderate_threshold: Maximum correlation value to be considered weak (i.e., below this is weak)\n",
    "weak_threshold = 0.3\n",
    "moderate_threshold = 0.5\n",
    "\n",
    "# Create a mask that filters correlations between weak_threshold and moderate_threshold\n",
    "# abs() is used to ensure we are considering the absolute correlation values (both positive and negative correlations)\n",
    "# The mask will be True for correlations that meet the weak correlation criteria\n",
    "mask = (corr_matrix.abs() >= weak_threshold) & (corr_matrix.abs() < moderate_threshold)\n",
    "# Apply the mask to the correlation matrix to extract weak correlations\n",
    "# where() keeps only the correlations that match the mask, and all others are set to NaN\n",
    "moderate_correlations = corr_matrix.where(mask)\n",
    "# Drop rows and columns where all values are NaN (i.e., where no correlations met the weak criteria)\n",
    "moderate_correlations.dropna(how='all', axis=0).dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEYRZ5EbA3hj"
   },
   "source": [
    "Now let's analyze the relationships between features using hierarchical clustering to identify groups of correlated features within our dataset. We visualize this clustering in a dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4E2hS2V-AjGc"
   },
   "outputs": [],
   "source": [
    "# Perform hierarchical clustering\n",
    "# '1 - abs(corr_matrix)' converts the correlation matrix into a distance matrix\n",
    "# Hierarchical clustering requires a distance matrix, and by subtracting from 1, we treat high correlations as \"close\" and low correlations as \"far\"\n",
    "# 'method=\"ward\"' is used to minimize the variance of the clusters being merged\n",
    "linkage_matrix = linkage(1 - abs(corr_matrix), method='ward')\n",
    "\n",
    "# Generate the dendrogram\n",
    "# 'labels=corr_matrix.columns' ensures the feature names (columns) are displayed on the x-axis\n",
    "# 'leaf_rotation=90' rotates the feature labels for readability\n",
    "plt.figure(figsize=(6,3))\n",
    "dendrogram(linkage_matrix, labels=corr_matrix.columns, leaf_rotation=90)\n",
    "plt.title(\"Dendrogram of Correlated Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtHM6bFHp6BY"
   },
   "source": [
    "<details>\n",
    "<summary>Discussion of results dendrogram</summary>\n",
    "\n",
    "**Discussion of results**<br>\n",
    "The dendrogram shows four clusters of features. The first cut-off in the dendrogram is at 0.8. At this value activity_level and used_calculator are clustered. Also market_value and city_size have almost the same cut-off value.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGxH9xuyFKGg"
   },
   "source": [
    "**⭐ Exercise:**<br>\n",
    "Above, we have a dendrogram that shows the features closest to each other. We can organize SHAP values according to the clusters in the dendrogram from most important to least important in groups (when applicable).<br>\n",
    "\n",
    "What to do: In the bar plot below use a clustering method and base it on the dendrogram above. Additionally, set a cutoff value for the minimum distance to capture only the most reliable relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PBzxLoXqFiz"
   },
   "outputs": [],
   "source": [
    "# Generate a SHAP bar plot with hierarchical clustering\n",
    "\n",
    "# The hierarchical clustering outcomes are passed as the 'clustering' argument\n",
    "# 'clustering_cutoff=X' controls where the dendrogram will be cut off to form clusters.\n",
    "# Features below this threshold are grouped together.\n",
    "shap.plots.bar(shap_values_all, clustering=, clustering_cutoff=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tY5ljnS0gJvk"
   },
   "source": [
    "**⭐ Exercise**<br>\n",
    "To get a clearer picture of how the clustered features interact, we can use dependence plots. These plots show how SHAP values for one feature change in relation to another (interactive) feature.<br>\n",
    "\n",
    "What to do: Plot a dependence plot between the top two clustered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPQqKcGqWuZZ"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# SHAP dependence plot for feature 1 showing interaction with feature 2\n",
    "shap.dependence_plot('', shap_values, dataShap, x_jitter=1, interaction_index='')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZWB_QxQFgop"
   },
   "source": [
    "<details>\n",
    "<summary>Discussion of the results</summary>\n",
    "\n",
    "**Discussion of results**<br>\n",
    "Activity level and used calculator are connected but not correlated enough to produce issues. It's worth looking at them together, as used calculator is a subset of activity.\n",
    "From the dependence plot we see:<br>\n",
    "* for values at 0, SHAP values are mostly near negative and zero, while\n",
    "* for values = 1, SHAP values are positive.\n",
    "\n",
    "This indicates a positive impact on predictions when a calculator is used. When calculator was not used, the effect is almost negligible. The color (representing activity_level) is generally uniform, though lower activity levels slightly correspond to lower SHAP values when calulator is not used.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgdi_VzBnVv0"
   },
   "source": [
    "## 2.2 SHAP and highly correlated features\n",
    "\n",
    " In this exercise, you will explore the SHAP values of highly correlated features. Our dataset doesn't have a highly correlated feature, hence we will add it. We will show how SHAP and highly correlated features look like and how to recognise it through explainability.\n",
    "\n",
    "**Exercise steps**:<br>\n",
    "* Add two randomly generated highly correlated features to the dataset.\n",
    "* Calculate the SHAP values and look at the plots.\n",
    "* ⭐ Make dependence plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKuuz9GEnuFz"
   },
   "outputs": [],
   "source": [
    "# Create a copy of the original dataframe to work with\n",
    "df1 = df.copy()\n",
    "np.random.seed(0)\n",
    "# Add a new feature 'n_cos', which is a noisy cosine wave\n",
    "# np.linspace generates evenly spaced values between 0 and 2*pi over the length of the dataframe\n",
    "# np.cos calculates the cosine of these values, and np.random.normal adds some random noise to it\n",
    "df1['n_cos'] = np.cos(np.linspace(0, 2 * np.pi, df.shape[0])) + np.random.normal(0, 0.1, size=df.shape[0])\n",
    "# Add a feature 'n_correlated_noise_age' that is correlated with the 'age' and 'parties_count' columns\n",
    "# The feature is calculated as a linear combination of 'age' with random noise and 'parties_count'\n",
    "# np.random.normal introduces random variation around the age feature, and 0.5 is a scaling factor for both 'age' and 'parties_count'\n",
    "df1['n_correlated_noise_age'] = df1['age']*0.5*np.random.normal(1, 0.05, size=df.shape[0],)+0.5*df1['parties_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_9Zr3gUoK2M"
   },
   "outputs": [],
   "source": [
    "# Drop the 'churn' (target) and 'balance' features from the dataframe to create the feature matrix X_c\n",
    "# 'churn' is the target variable, and 'balance' is excluded from the features\n",
    "X_c = df1.drop(['churn','balance'],axis=1)\n",
    "X_train_c, X_test_c, y_train, y_test = train_test_split(X_c, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xg_cls_c = xgb.XGBClassifier().fit(X_train_c, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b7dC1MMeHHT"
   },
   "source": [
    "Now let's calculate SHAP plots for our previously tuned model and a new one with correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfz-5oRPuETh"
   },
   "outputs": [],
   "source": [
    "dataShap_c = X_test_c\n",
    "# Set the test data subset to visualize SHAP values for the model without 'balance' feature\n",
    "explainer_c = shap.TreeExplainer(xg_cls_c)\n",
    "shap_values_c = explainer_c.shap_values(dataShap_c)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "plt.subplot(1,2,1)\n",
    "shap.summary_plot(shap_values, dataShap, plot_size=None, show=False)\n",
    "plt.title('Features importance tuned model')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "shap.summary_plot(shap_values_c, dataShap_c, plot_size=None, show=False)\n",
    "plt.title('Features importance model with correlated features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_uImOEyeClE"
   },
   "source": [
    "<details>\n",
    "<summary>Discussion of the results</summary>\n",
    "\n",
    "**Discussion of the results**<br>\n",
    "In the model with correlated features; these features influence the importance of others, causing a redistribution of SHAP values. The plot on the right shows that correlated features introduce noise and redundancy, potentially reducing interpretability. This highlights the benefit of removing or reducing correlated features to create more concise models.<br>\n",
    "\n",
    "Features ranked below the correlated noise may still be important. These are often unique features that occur infrequently, which is why their importance appears lower in the model.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtMe7HYtgd4_"
   },
   "source": [
    "**⭐ Exercise**<br>\n",
    "Plot depenence plot between age and n_correlated_noise_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJGOezsYulHt"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# SHAP dependence plot for 'age' showing interaction with 'n_correlated_noise_age'\n",
    "shap.dependence_plot('', shap_values_c, dataShap_c, interaction_index='', x_jitter=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMq0VIgdbNuI"
   },
   "source": [
    "<details>\n",
    "<summary>Discussion of the results</summary>\n",
    "\n",
    "**Discussion of the results**<br>\n",
    "The depenece plot between age and n_correlated_noise_age shows us that as age (x-axis) increases, SHAP values rise (y-axis), but the correlated feature (n_correlated_noise_age - shown in colour) is redundant. XGBoost effectively handles this, making the feature obsolete as it adds no real value and only introduces noise into the model. It can be safely discarded.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziFP3oqO1ACO"
   },
   "source": [
    "**⭐ Exercise**<br>\n",
    "Experiment with different features correlations - fill variable to display. If you don't fill counter variable as in the above plot, it will you show the most interactive one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riuKC8QfzaHE"
   },
   "outputs": [],
   "source": [
    "feature = ''\n",
    "plt.figure()\n",
    "# SHAP dependence plot for 'eature with jitter for better point visibility\n",
    "shap.dependence_plot(feature, shap_values_c, dataShap_c, x_jitter=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWo2neslmzJD"
   },
   "source": [
    "# 3. Exercise Three: SHAP clustering\n",
    "This exercise aims to demonstrate an approach for extracting meaningful insights from our data and model to enhance explainability and interpretability. SHAP is a valuable tool for data scientists and developers to understand how their models make certain decisions. However, the corresponding plots and numbers may not be familiar to business stakeholders. To provide more business-oriented and easily understandable insights, we can leverage a new clustering technique that uses SHAP values to represent our data. Later, we use Skoperules to generate rules that help in understanding the characteristics of our clusters. The process is as follows:\n",
    "1. After training the model, calculate the SHAP values for our dataset.\n",
    "2. Use [UMAP](https://umap-learn.readthedocs.io/en/latest/) to reduce the dimensionality of the SHAP values to 2D.\n",
    "3. Apply [HDBSCAN](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html) to cluster the 2D embeddings of the SHAP values.\n",
    "4. Finally, use [Skoperules](https://skope-rules.readthedocs.io/en/latest/index.html) to extract more interpretable and linguistically understandable rules within each cluster.\n",
    "\n",
    "*Remark:* In exercises 3.1 and 3.2 you only need to run the code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocm3QqQFUZ28"
   },
   "source": [
    "## 3.1 Calculate SHAP values\n",
    "Calculate SHAP values to understand the contribution of each feature to the model's predictions. We'll do it on a subsample due to long run times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9RN32J4Umg6"
   },
   "outputs": [],
   "source": [
    "def get_shap_values(model: BaseEstimator, X: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute SHAP values for the given model and data.\n",
    "\n",
    "    Args:\n",
    "        model (BaseEstimator): Trained machine learning model.\n",
    "        X (pd.DataFrame): Feature data.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: SHAP values.\n",
    "    \"\"\"\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer(X).values\n",
    "    return shap_values\n",
    "\n",
    "# Let's take subsample for speed\n",
    "data_cluster = X_train.copy(deep=True)\n",
    "data_cluster['churn'] = y_train\n",
    "data_cluster = data_cluster.sample(20000, random_state = 42)\n",
    "X_cluster = data_cluster.drop('churn',axis=1)\n",
    "y_cluster = data_cluster['churn']\n",
    "\n",
    "shap_values_train = get_shap_values(xg_cls, X_cluster)\n",
    "print(f\"SHAP array size: {shap_values_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gr-JH3R6U70E"
   },
   "source": [
    "## 3.2 UMAP dimensionality reduction\n",
    "**UMAP** is a dimensionality reduction technique that preserves the local structure of high-dimensional data while effectively capturing its global structure, making it ideal for visualizing complex datasets in lower dimensions. Now, let's apply **UMAP** to project the high-dimensional SHAP values into two-dimensional space for easier visualization and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7tF1V5_VGyA"
   },
   "outputs": [],
   "source": [
    "def reduce_dimensionality(data: np.ndarray, n_components: int = 2, min_dist: float = 0, n_neighbors: int = 100) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reduce the dimensionality of the given data using UMAP.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Data to reduce dimensionality for.\n",
    "        n_components (int, optional): Number of dimensions to reduce to. Defaults to 2.\n",
    "        min_dist (float, optional): Minimum distance between neighboring points. Defaults to 0.\n",
    "        n_neighbors (int, optional): Number of nearest neighbors to consider. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Reduced dimensionality data.\n",
    "    \"\"\"\n",
    "    reducer = umap.UMAP(n_components=n_components, n_jobs=2, random_state=42, min_dist=min_dist, n_neighbors=n_neighbors)\n",
    "    embedding = reducer.fit_transform(data)\n",
    "    return embedding\n",
    "\n",
    "embedding = reduce_dimensionality(shap_values_train)\n",
    "print(f\"Embedding size: {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFsKQJfbVUrR"
   },
   "source": [
    "## 3.3 HDBSCAN clustering\n",
    "**HDBSCAN** is a density-based clustering algorithm that identifies clusters of varying shapes and sizes which enables discovering complex patterns in large datasets. Utilize **HDBSCAN** to identify and group similar patterns within 2D embeddings of the SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZ9Lq7zlVhTH"
   },
   "outputs": [],
   "source": [
    "def cluster_embeddings(embedding: np.ndarray, min_cluster_size: int, min_samples: int) -> Tuple[hdbscan.HDBSCAN, pd.Series]:\n",
    "    \"\"\"\n",
    "    Cluster UMAP embeddings using HDBSCAN.\n",
    "\n",
    "    Args:\n",
    "        embedding (np.ndarray): UMAP embeddings to cluster.\n",
    "        min_cluster_size (int): Minimum cluster size for HDBSCAN.\n",
    "        min_samples (int): Minimum samples for HDBSCAN.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[hdbscan.HDBSCAN, pd.Series]: HDBSCAN clusterer and cluster labels.\n",
    "    \"\"\"\n",
    "    hdbscan_clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples)\n",
    "    cluster_labels = hdbscan_clusterer.fit_predict(embedding)\n",
    "    return hdbscan_clusterer, pd.Series(cluster_labels)\n",
    "\n",
    "min_cluster_size = 800\n",
    "min_samples = 300\n",
    "hdbscan_clusterer, cluster_labels = cluster_embeddings(embedding, min_cluster_size, min_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFZTPnTmtnRO"
   },
   "source": [
    "📖 To learn more about the 'min_cluster_size' and 'min_samples' parameters in **HDBSCAN** take a look at this informative [blog post](https://walmsley.dev/posts/hdbscan-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L20JbjfMVqzr"
   },
   "outputs": [],
   "source": [
    "number_of_clusters = cluster_labels.nunique()\n",
    "print(f\"Number of clusters: {number_of_clusters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tCWObsVWJKW"
   },
   "source": [
    "**2D plot** of **embeddings** with their corresponding cluster labels vs customers that churn.<br>\n",
    "Do you see any clusters defining mostly churners or non churners?<br>\n",
    "Tip: samples that didn't match any clustering criteria are labelled -1. Always check if it's not too many of them, otherwise you need to adjust your UMAP parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhJ2Z-fMWHcY"
   },
   "outputs": [],
   "source": [
    "def plot_clusters(embedding: np.ndarray, cluster_labels: pd.Series, target: pd.Series, mask:int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Plot the given points using a scatter plot, coloring them based on cluster labels.\n",
    "\n",
    "    Args:\n",
    "        embedding (np.ndarray): Reduced dimensionality data.\n",
    "        cluster_labels (pd.Series): Cluster labels for coloring points.\n",
    "        target(pd.Series): Target variable of the model\n",
    "        mask (int, optional): Indicator if to mask to filter outlier points. Defaults to 0.\n",
    "    \"\"\"\n",
    "    # Filter out points with cluster label -1, since they're outliers\n",
    "    if mask == 0:\n",
    "      mask = cluster_labels != -2\n",
    "    else:\n",
    "      mask = cluster_labels != -1\n",
    "    filtered_embedding = embedding[mask]\n",
    "    filtered_cluster_labels = cluster_labels[mask]\n",
    "    target = target.reset_index().drop('index',axis=1)[mask]\n",
    "    #plt.figure(figsize=(10, 8))\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    palette = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "    plt.subplot(1,2,1)\n",
    "    if len(filtered_cluster_labels.unique())>2:\n",
    "      sns.scatterplot(x=filtered_embedding[:, 0], y=filtered_embedding[:, 1], hue=filtered_cluster_labels, palette=palette, legend=\"full\", s=50)\n",
    "    else:\n",
    "      sns.scatterplot(x=filtered_embedding[:, 0], y=filtered_embedding[:, 1], hue=filtered_cluster_labels, legend=\"full\", s=50)\n",
    "    plt.title('Cluster plot')\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.scatterplot(x=filtered_embedding[:, 0], y=filtered_embedding[:, 1],hue = target.values.ravel(), palette = sns.color_palette(\"viridis\", 2))\n",
    "    plt.title(\"Cluster Plot vs churn\")\n",
    "    plt.show()\n",
    "plot_clusters(embedding, cluster_labels, y_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3Mnh7t3jNur"
   },
   "source": [
    "⭐ **Exercise:** \\\n",
    "In this exercise, you will explore how different variables are represented in the clusters. Are there clusters that contain solely specific values?\n",
    "Check it out!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pz9THcjGjrV5"
   },
   "outputs": [],
   "source": [
    "feature = ''\n",
    "feature_vals = X_cluster.reset_index().drop('index',axis=1)[feature]\n",
    "palette_feat = sns.color_palette(\"viridis\", len(feature_vals.unique()))\n",
    "plt.figure()\n",
    "sns.scatterplot(x=embedding[:, 0], y=embedding[:, 1], hue=feature_vals, legend=\"full\", s=50, palette = palette_feat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOk4079RWfQB"
   },
   "source": [
    "## 3.4 Bonus: Skoperules to extract meaningful insights\n",
    "**Skoperules** is a rule-based machine learning algorithm that generates interpretable decision rules from clustered data, enabling users to understand and visualize the relationships between features and target variables in an understandable format. Employ **Skoperules** to derive clear and human-readable rules that explain the characteristics of each cluster in our data.<br>\n",
    "We will extract rules of the clusters, the metris and the churn rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKc5rRWZqgxF"
   },
   "outputs": [],
   "source": [
    "number_of_clusters = cluster_labels[cluster_labels!=-1].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5NiNbZuxbct"
   },
   "outputs": [],
   "source": [
    "df_clusters = pd.DataFrame(columns=['cluster', 'rule', 'metrics (precision, recall)', 'clust_size', 'churn_rate'])\n",
    "for cluster in range(number_of_clusters):\n",
    "    X_cluster_r = X_cluster.copy(deep=True)\n",
    "    X_cluster_r = X_cluster_r.reset_index().drop('index',axis=1)\n",
    "    mask = cluster_labels != -1\n",
    "    X_cluster_r_m = X_cluster_r[mask]\n",
    "    filtered_cluster_labels = cluster_labels[mask]\n",
    "    y_target = (filtered_cluster_labels == cluster)*1\n",
    "\n",
    "    churn_rate = y_cluster.reset_index().drop('index',axis=1).loc[y_target[y_target==1].index]\n",
    "    size_clust = len(churn_rate)\n",
    "    churn_rate = np.sum(churn_rate)/size_clust\n",
    "\n",
    "    model = SkopeRules(max_depth = 4,feature_names=X_cluster_r_m.columns.to_list())\n",
    "    model.fit(X_cluster_r_m, y_target)\n",
    "    readable_rules = {}\n",
    "    rules = model.rules_\n",
    "    if len(rules)>1:\n",
    "        rules = [rules[0]]\n",
    "    for rule, metrics in rules:\n",
    "        new_row = pd.DataFrame({\"cluster\":cluster, 'rule':rule, 'metrics (precision, recall)':[metrics], 'clust_size':size_clust, 'churn_rate':churn_rate})\n",
    "        df_clusters = pd.concat([df_clusters, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4i5tp-zx_Cn"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "display(df_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWRgfgb4gzcN"
   },
   "source": [
    "<details>\n",
    "<summary> Dissucion of the results and next steps </summary>\n",
    "\n",
    "**Discussion of the results and next steps**<br>\n",
    "Each of these clusters describes different personas. Some of them have higher probability of churning. In metrics precision and recall describe for us quality of clusters. You can deep dive in specific clusters and use skoperules to identify subgroup of churners within each persona. You simply give Skoperules data with features for only one cluster with target variable of churning instead of cluster number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6os_u1URDvtf"
   },
   "source": [
    "# Bonus exercise 1 - simple tree comparison\n",
    "\n",
    "In this bonus exercise you will compare your results with simple explainable decision tree. A decision tree is composed of nodes and branches. The topmost node is called the root and represents the full dataset. Each internal node represents a feature (or attribute), each branch represents a decision rule, and each leaf node represents an outcome or class label. As you move down the tree, each node splits the data based on a feature. The split of the tree has been performed based on [Gini impurity](https://medium.com/@arpita.k20/gini-impurity-and-entropy-for-decision-tree-68eb139274d1). Each branch leads to another node or a leaf. Decision trees can also provide insights into feature importance. Features that appear closer to the root generally have more influence on the predictions.\n",
    "\n",
    "⭐ **Exercise:**\n",
    "Look at the outcomes of simple model and compare to results you have seen in the workshop. Does this tree make same decisions as more complicated algorithm? Do we get the same insights on our customer population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhPCaucrD1V-"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "X = df.drop(['churn','balance'],axis=1)\n",
    "y = df['churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "plt.figure(figsize=(15,8))\n",
    "tree.plot_tree(model, feature_names=list(X.columns), fontsize=10, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5ivBeIl0HLz"
   },
   "source": [
    "# Further readings\n",
    "\n",
    "## SHAP documentation\n",
    "Very good source on information, provides examples, issues and of course typical docummentation.\n",
    "https://shap.readthedocs.io/en/latest/\n",
    "\n",
    "## SHAP Tree (Explainer)\n",
    "https://medium.com/analytics-vidhya/shap-part-3-tree-shap-3af9bcd7cd9b\n",
    "https://shap.readthedocs.io/en/latest/generated/shap.TreeExplainer.html\n",
    "\n",
    "## SHAP dashboard\n",
    "\n",
    "If you want to interact with your model outcomes/explanations, you can also use shapash library that automatically can create simple interactive dashboard. Example: https://shapash-demo.ossbymaif.fr/\n",
    "\n",
    "## SHAP clustering\n",
    "* UMAP<br>\n",
    "  https://umap-learn.readthedocs.io/en/latest/\n",
    "* HBDSCAN<br>\n",
    "  https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html<br>\n",
    "  https://walmsley.dev/posts/hdbscan-parameters\n",
    "* Skoperules<br>\n",
    "  https://skope-rules.readthedocs.io/en/latest/index.html\n",
    "\n",
    "## Examples of other methods\n",
    "| Method                      | Description                                                                | Context                                                                                     | Example Libraries                                                                                 |\n",
    "|-----------------------------|----------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| **Counterfactual Explanations** | Show the smallest change in feature values <br>to alter the prediction.      | Useful for understanding what changes could result <br>in different outcomes, such as loan approvals. | [DICE](https://interpret.ml/DiCE/) |\n",
    "| **What-If Tool**           | Allows users to change feature values <br>and see how the predictions change.   | Useful for interactive exploration of model behavior <br>and decision-making scenarios.         | [What-If Tool](https://pair-code.github.io/what-if-tool/) |\n",
    "| **Feature Importances**    | Measures how often a feature is used <br> and how much it helps improve predictions. | Part of tree models                   | [sklearn FI](https://scikit-learn.org/stable/modules/ensemble.html#feature-importance-evaluation), [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html)|\n",
    "| **Permutation Feature Importance** | Importance assessed by measuring performance <br>change when a feature is shuffled. | Provides a model-agnostic assessment of feature significance.                               | [sklearn PI](https://scikit-learn.org/stable/modules/permutation_importance.html) |\n",
    "| **PDP Plots**              | Show the marginal effect of one or two features <br>on the prediction.         | Useful for understanding the relationship between features <br>and predictions.                |  [sklearn PDP](https://scikit-learn.org/stable/modules/partial_dependence.html) |\n",
    "\n",
    "More on interpretable ML: https://christophm.github.io/interpretable-ml-book/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5815996,
     "sourceId": 9546269,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
